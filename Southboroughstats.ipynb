{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4, pandas, re, datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4\n",
    "\n",
    "r = requests.get('https://southboroughcc.play-cricket.com/website/results/4462297')\n",
    "r.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(r.content, 'html.parser')\n",
    "r.text\n",
    "rows = []\n",
    "inningsno = r.text[r.text.find(\"innings\")+len(\"innings\"):r.text.find(\"-\",r.text.find(\"innings\"))]\n",
    "for i in range(1,12):\n",
    "    rows.append(soup.select('#innings'+ inningsno +' > div.table-responsive-sm > table.table.standm.table-hover > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(4) > strong'))\n",
    "## Extracts all batting scores within <strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(r.text).find(\"innings\")\n",
    "str(r.text).find(\"-\",24020)\n",
    "str(r.text)[24034:24038]\n",
    "r.text.find(\"innings\")\n",
    "r.text.find(\"-\",r.text.find(\"innings\"))\n",
    "r.text[r.text.find(\"innings\")+len(\"innings\"):r.text.find(\"-\",r.text.find(\"innings\"))]\n",
    "## Finds the innnings number as defined in Play-Cricket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4\n",
    "\n",
    "r2 = requests.get('https://southboroughcc.play-cricket.com/website/results/4462297')\n",
    "r2.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(r2.content, 'html.parser')\n",
    "elems = soup.select('#innings5411478 > div.table-responsive-sm > table.table.standm.table-hover > tbody > tr:nth-child(1)')\n",
    "## batting scorecard table for first innings - nth child 1-11 are each batsman's row\n",
    "\n",
    "elems[0].find_all('td')[0].find_all('div')[0].find_all('sup') ## find_all('td') finds all of the 'cells' of data in row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4\n",
    "\n",
    "r3 = requests.get('https://southboroughcc.play-cricket.com/website/results/4462297')\n",
    "r3.raise_for_status()\n",
    "soup3 = bs4.BeautifulSoup(r3.content, 'html.parser')\n",
    "#elems3 = soup3.select('#innings5411478 > table > tbody') ##bowling scorecard for first innings\n",
    "elems3 = soup3.select('#innings5411478 > table')\n",
    "#elems3[0].find_all('td')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "table = pandas.read_html(str(elems3[0]))[0] #Generates Panda table of bowling scorecard. Much easier to use than html extraction\n",
    "table[[\"BOWLER\",\"OVERSO\"]]\n",
    "len(table)\n",
    "#for i in range(len(table)):\n",
    "    #print(table.iloc[[i]])\n",
    "#table.columns.values[1]\n",
    "table.iloc[[3]].values[0]#[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 0, 0, 10, 0, 0, 0, 0]\n",
      "['INVICTA JUNIOR CRICKET LEAGUE', 'U13 Tunbridge Wells Division 1']\n",
      "['', datetime.date(2020, 7, 26)]\n"
     ]
    }
   ],
   "source": [
    "### Overall match stats\n",
    "\n",
    "##Extracts match point data\n",
    "\n",
    "GamePoints_data = []\n",
    "\n",
    "for i in range(1,3):\n",
    "    GamePoints = soup4.select('#multiCollapseExample' + str(i) + ' > table')\n",
    "    \n",
    "    if len(GamePoints) == 0:\n",
    "        GamePoints_data = [\"NaN\"]*10\n",
    "        \n",
    "    else:\n",
    "        GamePoints_table = pandas.read_html(str(GamePoints[0]))[0]\n",
    "        for j in range(len(GamePoints_table)):\n",
    "            GamePoints_data.append(GamePoints_table.iloc[[j]].values[0][1])\n",
    "\n",
    "print(GamePoints_data)        \n",
    "        \n",
    "##Extracts division and league data\n",
    "\n",
    "DivisionInfo = soup4.select('body > div.breadcrumb-league-wrapper > div.container.breadcrumb-league > div > div.col-sm-12.col-md-6.col-lg-6.text-center.text-lg-left.leaguedetail-left')\n",
    "DivisionInfo_data = [\"\",\"\"]\n",
    "\n",
    "if 'friendly' in str(DivisionInfo[0]).lower():\n",
    "    DivisionInfo_data = [\"Friendly\", \"Friendly\"]\n",
    "\n",
    "elif DivisionInfo[0].find_all('span')[0].contents[0].strip() == \"\":\n",
    "    DivisionInfo_data = [DivisionInfo[0].find_all('span')[2].contents[0].strip()]*2\n",
    "    \n",
    "elif 'https' in str(DivisionInfo[0].find_all('span')[2].contents[1]).lower():\n",
    "    DivisionInfo_data[0] = DivisionInfo[0].find_all('span')[0].contents[0].strip()\n",
    "    start = str(DivisionInfo[0].find_all('span')[2].contents[1]).find(\">\") + 1 \n",
    "    end = str(DivisionInfo[0].find_all('span')[2].contents[1]).find(\"<\",str(DivisionInfo[0].find_all('span')[2].contents[1]).find(\">\")) \n",
    "    DivisionInfo_data[1] = str(DivisionInfo[0].find_all('span')[2].contents[1])[start:end]\n",
    "    \n",
    "print(DivisionInfo_data)\n",
    "\n",
    "##Extracts date and location data\n",
    "\n",
    "DateGround_data = [\"\",\"\"]\n",
    "\n",
    "DateGround = soup4.select('body > div.breadcrumb-league-wrapper > div.container.breadcrumb-league > div > div.col-sm-12.col-md-6.col-lg-6.text-lg-right.leaguedetail-right')\n",
    "Date = parse(re.search('\\d*? \\w* \\d{4}',DateGround[0].text)[0])\n",
    "Ground = DateGround[0].find_all('a')[0].contents[0]\n",
    "\n",
    "if \"\\n\" not in Ground:\n",
    "    DateGround_data[0] = Ground\n",
    "DateGround_data[1] = Date.date()\n",
    "\n",
    "print(DateGround_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test webpages ####\n",
    "\n",
    "\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/4462297') # Division / League\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/4428817') # Friendly\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/27378') # No division just league\n",
    "r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/412586') # no division and no ground\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/4413968') # u13 and abandonded\n",
    "\n",
    "r4.raise_for_status()\n",
    "soup4 = bs4.BeautifulSoup(r4.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"team-info-2\">\n",
       "<span class=\"team-info-1\">\n",
       "              1st XI \n",
       "            </span>\n",
       "            178 <span class=\"smalltxt\">  / All out  (39.5) </span>\n",
       "</p>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Teams = soup4.select('body > div.container.main-header.main-header-lg.d-none.d-lg-block > table')\n",
    "\n",
    "# Teams_data = [\"\",\"\"]\n",
    "\n",
    "# for i in range(2):\n",
    "#     Clubname = Teams[0].find_all('p', class_=\"team-name\")[i].contents[0]\n",
    "#     first = str(Teams[0].find_all('p', class_=\"team-info-2\")[i].find_all(class_ = \"team-info-1\")[0]).find(\"\\n\")\n",
    "#     second = str(Teams[0].find_all('p', class_=\"team-info-2\")[i].find_all(class_ = \"team-info-1\")[0]).find(\"\\n\", first + 1)\n",
    "#     Clubteam = str(Teams[0].find_all('p', class_=\"team-info-2\")[i].find_all(class_ = \"team-info-1\")[0])[first+1:second].strip()\n",
    "#     Teams_data[i] = Clubname + ' ' + Clubteam\n",
    "\n",
    "# print(Teams_data)\n",
    "\n",
    "\n",
    "str(Teams[0].find_all('p', class_ = \"team-info-2\")[0]).find(\"</span\")\n",
    "Teams[0].find_all('p', class_ = \"team-info-2\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
