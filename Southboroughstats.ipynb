{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4, pandas, re, datetime, numpy\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4\n",
    "\n",
    "r = requests.get('https://southboroughcc.play-cricket.com/website/results/4462297')\n",
    "r.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(r.content, 'html.parser')\n",
    "r.text\n",
    "rows = []\n",
    "inningsno = r.text[r.text.find(\"innings\")+len(\"innings\"):r.text.find(\"-\",r.text.find(\"innings\"))]\n",
    "for i in range(1,12):\n",
    "    rows.append(soup.select('#innings'+ inningsno +' > div.table-responsive-sm > table.table.standm.table-hover > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(4) > strong'))\n",
    "## Extracts all batting scores within <strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(r.text).find(\"innings\")\n",
    "str(r.text).find(\"-\",24020)\n",
    "str(r.text)[24034:24038]\n",
    "r.text.find(\"innings\")\n",
    "r.text.find(\"-\",r.text.find(\"innings\"))\n",
    "r.text[r.text.find(\"innings\")+len(\"innings\"):r.text.find(\"-\",r.text.find(\"innings\"))]\n",
    "## Finds the innnings number as defined in Play-Cricket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4\n",
    "\n",
    "r2 = requests.get('https://southboroughcc.play-cricket.com/website/results/4462297')\n",
    "r2.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(r2.content, 'html.parser')\n",
    "elems = soup.select('#innings5411478 > div.table-responsive-sm > table.table.standm.table-hover > tbody > tr:nth-child(1)')\n",
    "## batting scorecard table for first innings - nth child 1-11 are each batsman's row\n",
    "\n",
    "elems[0].find_all('td')[0].find_all('div')[0].find_all('sup') ## find_all('td') finds all of the 'cells' of data in row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4\n",
    "\n",
    "r3 = requests.get('https://southboroughcc.play-cricket.com/website/results/4462297')\n",
    "r3.raise_for_status()\n",
    "soup3 = bs4.BeautifulSoup(r3.content, 'html.parser')\n",
    "#elems3 = soup3.select('#innings5411478 > table > tbody') ##bowling scorecard for first innings\n",
    "elems3 = soup3.select('#innings5411478 > table')\n",
    "#elems3[0].find_all('td')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "table = pandas.read_html(str(elems3[0]))[0] #Generates Panda table of bowling scorecard. Much easier to use than html extraction\n",
    "table[[\"BOWLER\",\"OVERSO\"]]\n",
    "len(table)\n",
    "#for i in range(len(table)):\n",
    "    #print(table.iloc[[i]])\n",
    "#table.columns.values[1]\n",
    "table.iloc[[3]].values[0]#[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 3, 5, 8, 20, 0, 0, 0, 20]\n",
      "['KENT COUNTY VILLAGE LEAGUE', 'Corona League Tier 2 Division A']\n",
      "['Limpsfield Chart Cricket Club', datetime.date(2020, 8, 22)]\n",
      "['Limpsfield Chart CC 1st XI', 'Southborough CC 1st XI', '184', '209', 10, 10, '39.4', '40', 'Southborough CC 1st XI', '25', '', '', 'Limpsfield Chart CC 1st XI', 'Field']\n"
     ]
    }
   ],
   "source": [
    "### Overall match stats\n",
    "\n",
    "##Extracts match point data [Home game, home penalty, home batting, home bowling, home total, away game, away penalty, away batting , away bowling, away total]\n",
    "\n",
    "GamePoints_data = []\n",
    "\n",
    "for i in range(1,3):\n",
    "    GamePoints = soup4.select('#multiCollapseExample' + str(i) + ' > table')\n",
    "    \n",
    "    if len(GamePoints) == 0:\n",
    "        GamePoints_data = [\"NaN\"]*10\n",
    "        \n",
    "    else:\n",
    "        GamePoints_table = pandas.read_html(str(GamePoints[0]))[0]\n",
    "        for j in range(len(GamePoints_table)):\n",
    "            GamePoints_data.append(GamePoints_table.iloc[[j]].values[0][1])\n",
    "\n",
    "print(GamePoints_data)        \n",
    "        \n",
    "##Extracts division and league data [league , division]\n",
    "\n",
    "DivisionInfo = soup4.select('body > div.breadcrumb-league-wrapper > div.container.breadcrumb-league > div > div.col-sm-12.col-md-6.col-lg-6.text-center.text-lg-left.leaguedetail-left')\n",
    "DivisionInfo_data = [\"\"]*2\n",
    "\n",
    "if 'friendly' in str(DivisionInfo[0]).lower():\n",
    "    DivisionInfo_data = [\"Friendly\", \"Friendly\"]\n",
    "\n",
    "elif DivisionInfo[0].find_all('span')[0].contents[0].strip() == \"\":\n",
    "    DivisionInfo_data = [DivisionInfo[0].find_all('span')[2].contents[0].strip()]*2\n",
    "    \n",
    "elif 'https' in str(DivisionInfo[0].find_all('span')[2].contents[1]).lower():\n",
    "    DivisionInfo_data[0] = DivisionInfo[0].find_all('span')[0].contents[0].strip()\n",
    "    start = str(DivisionInfo[0].find_all('span')[2].contents[1]).find(\">\") + 1 \n",
    "    end = str(DivisionInfo[0].find_all('span')[2].contents[1]).find(\"<\",str(DivisionInfo[0].find_all('span')[2].contents[1]).find(\">\")) \n",
    "    DivisionInfo_data[1] = str(DivisionInfo[0].find_all('span')[2].contents[1])[start:end]\n",
    "    \n",
    "print(DivisionInfo_data)\n",
    "\n",
    "##Extracts date and location data [ground , date]\n",
    "\n",
    "DateGround_data = [\"\"]*2\n",
    "\n",
    "DateGround = soup4.select('body > div.breadcrumb-league-wrapper > div.container.breadcrumb-league > div > div.col-sm-12.col-md-6.col-lg-6.text-lg-right.leaguedetail-right')\n",
    "Date = parse(re.search('\\d*? \\w* \\d{4}',DateGround[0].text)[0])\n",
    "Ground = DateGround[0].find_all('a')[0].contents[0]\n",
    "\n",
    "if \"\\n\" not in Ground:\n",
    "    DateGround_data[0] = Ground\n",
    "DateGround_data[1] = Date.date()\n",
    "\n",
    "print(DateGround_data)\n",
    "\n",
    "\n",
    "\n",
    "## Extracts [Home team, Away team, Home batting score, Away batting score, Home wickets lost, Away wickets lost, Home overs, Away overs, Winner, by runs, by wickets, other, toss winner, toss decision]\n",
    "\n",
    "Teams = soup4.select('body > div.container.main-header.main-header-lg.d-none.d-lg-block > table')\n",
    "\n",
    "Teams_data = [\"\"]*14\n",
    "\n",
    "for i in range(2):\n",
    "    Clubname = Teams[0].find_all('p', class_=\"team-name\")[i].contents[0]\n",
    "    first = str(Teams[0].find_all('p', class_=\"team-info-2\")[i].find_all(class_ = \"team-info-1\")[0]).find(\"\\n\")\n",
    "    second = str(Teams[0].find_all('p', class_=\"team-info-2\")[i].find_all(class_ = \"team-info-1\")[0]).find(\"\\n\", first + 1)\n",
    "    Clubteam = str(Teams[0].find_all('p', class_=\"team-info-2\")[i].find_all(class_ = \"team-info-1\")[0])[first+1:second].strip()\n",
    "    Teams_data[i] = Clubname + ' ' + Clubteam\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    first = str(Teams[0].find_all('p', class_ = \"team-info-2\")[i]).find(\"</span>\\n\")\n",
    "    second = str(Teams[0].find_all('p', class_ = \"team-info-2\")[i]).find(\"<\", first + 1)\n",
    "    Battingscore = str(Teams[0].find_all('p', class_ = \"team-info-2\")[i])[first + len(\"</span>\\n\") : second].strip()\n",
    "    Teams_data[2 + i] = Battingscore\n",
    "    \n",
    "\n",
    "for i in range(2):\n",
    "    if len(Teams[0].find_all('p', class_ = \"team-info-2\")[i].find_all(class_ = \"smalltxt\")) == 0:\n",
    "        Teams_data[4 + i], Teams_data[6 + i] = \"\",\"\"\n",
    "    else :\n",
    "        WicketsOvers_html = Teams[0].find_all('p', class_ = \"team-info-2\")[i].find_all(class_ = \"smalltxt\")[0].contents[0]\n",
    "        first = WicketsOvers_html.find(\"/\")\n",
    "        second = WicketsOvers_html.find(\"(\", first + 1)\n",
    "        third = WicketsOvers_html.find(\")\", second + 1)\n",
    "        Wickets = WicketsOvers_html[first + 1 : second].strip()\n",
    "        if \"All out\" in Wickets:\n",
    "            Teams_data[4 + i] = 10\n",
    "        else :\n",
    "            Teams_data[4 + i] = Wickets\n",
    "        Overs = WicketsOvers_html[second + 1 : third].strip()\n",
    "        Teams_data[6 + i] = Overs\n",
    "\n",
    "        \n",
    "if \"ABANDONED\" in str(Teams[0]):\n",
    "    Teams_data[8] = \"None\"\n",
    "    Teams_data[11] = \"Abandoned\"\n",
    "\n",
    "elif \"CONCEDED\" in str(Teams[0]):\n",
    "    Teamconceded = Teams[0].find_all('p', class_ = \"match-ttl win-cb-name\")[0].contents[0].strip()\n",
    "    if Teamconceded in Teams_data[0].upper():\n",
    "        Teams_data[8] = Teams_data[1]\n",
    "    else :\n",
    "        Teams_data[8] = Teams_data[0]\n",
    "    Teams_data[11] = \"Conceded\"\n",
    "    \n",
    "else :\n",
    "    Matchwinner = Teams[0].find_all('p', class_ = \"match-ttl win-cb-name\")[0].contents[0].strip()\n",
    "    first = str(Teams[0].find_all('div', class_ = \"info mdont\")[0].contents[1]).find(\"<span>\")\n",
    "    second = str(Teams[0].find_all('div', class_ = \"info mdont\")[0].contents[1]).find(\"<\", first + 1)\n",
    "    Wintype = str(Teams[0].find_all('div', class_ = \"info mdont\")[0].contents[1])[first + len(\"<span>\") : second]\n",
    "    Byhowmuch = ''.join(filter(str.isdigit, str(Teams[0].find_all('div', class_ = \"info mdont\")[0].contents[0])))\n",
    "\n",
    "    if Matchwinner in Teams_data[0].upper():\n",
    "        Teams_data[8] = Teams_data[0]\n",
    "    else :\n",
    "        Teams_data[8] = Teams_data[1]\n",
    "    if Wintype == \"RUNS\":\n",
    "            Teams_data[9] = Byhowmuch\n",
    "    if Wintype == \"WICKETS\":\n",
    "            Teams_data[10] = Byhowmuch      \n",
    "\n",
    "            \n",
    "if len(Teams[0].find_all('p', class_ = \"team-info-3\")) != 0:\n",
    "    for i in range(2):\n",
    "        if len(Teams[0].find_all('p', class_ = \"team-info-3\")[i].contents) != 0:\n",
    "            Teams_data[12] = Teams_data[i]\n",
    "            if \"bat\" in Teams[0].find_all('p', class_ = \"team-info-3\")[i].contents[0]:\n",
    "                Teams_data[13] = \"Bat\"\n",
    "            else :\n",
    "                Teams_data[13] = \"Field\"\n",
    "\n",
    "    if Teams_data[12] == \"\" and Teams_data[13] == \"\":\n",
    "        Teams_data[12], Teams_data[13] = \"No toss\", \"No toss\"\n",
    "        \n",
    "elif len(Teams[0].find_all('p', class_ = \"team-info-3 adma\")) != 0:\n",
    "    for i in range(2):\n",
    "        if len(Teams[0].find_all('p', class_ = \"team-info-3 adma\")[i].contents) != 0:\n",
    "            Teams_data[12] = Teams_data[i]\n",
    "            if \"bat\" in Teams[0].find_all('p', class_ = \"team-info-3 adma\")[i].contents[0]:\n",
    "                Teams_data[13] = \"Bat\"\n",
    "            else :\n",
    "                Teams_data[13] = \"Field\"\n",
    "\n",
    "    if Teams_data[12] == \"\" and Teams_data[13] == \"\":\n",
    "        Teams_data[12], Teams_data[13] = \"No toss\", \"No toss\"            \n",
    "            \n",
    "print(Teams_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test webpages ####\n",
    "\n",
    "\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/4462297') # Division / League\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/4428817') # Friendly\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/27378') # No division just league\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/412586') # no division, no ground, abandoned\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/4413968') # u13, conceded\n",
    "#r4 = requests.get('https://southboroughcc.play-cricket.com/website/results/4462178') # team won tost and field first, and won by runs\n",
    "\n",
    "r4.raise_for_status()\n",
    "soup4 = bs4.BeautifulSoup(r4.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Limpsfield Chart CC 1st XI', 'Southborough CC 1st XI', '184', '209', 10, 10, '39.4', '40', 'Southborough CC 1st XI', '25', '', '', 'Limpsfield Chart CC 1st XI', 'Field']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Teams[0].find_all('p', class_ = \"team-info-3 adma\")[0].contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
